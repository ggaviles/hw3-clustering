{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db22420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster import KMeans, make_clusters\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import defaultdict\n",
    "\n",
    "from matplotlib.pyplot import plot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fa70769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluster import KMeans\n",
    "class Kplusplus(KMeans):\n",
    "    def fit(self, mat: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fits the kmeans algorithm onto a provided 2D matrix.\n",
    "        As a bit of background, this method should not return anything.\n",
    "        The intent here is to have this method find the k cluster centers from the data\n",
    "        with the tolerance, then you will use .predict() to identify the\n",
    "        clusters that best match some data that is provided.\n",
    "\n",
    "        In sklearn there is also a fit_predict() method that combines these\n",
    "        functions, but for now we will have you implement them both separately.\n",
    "\n",
    "        inputs:\n",
    "            mat: np.ndarray\n",
    "                A 2D matrix where the rows are observations and columns are features\n",
    "        \"\"\"\n",
    "        # Create an initial centroid\n",
    "        self._generate_init_centroid(mat)\n",
    "\n",
    "        # Generate k centroids\n",
    "        self._generate_k_centroids(mat)\n",
    "\n",
    "        # Calculate the sum of squares error for this first set of k centroids\n",
    "        prev_error = self._generate_error_per_centroid(mat)\n",
    "\n",
    "        # No other error here so set error_diff to prev_error\n",
    "        curr_error = prev_error\n",
    "\n",
    "        error_diff_dict = {}\n",
    "\n",
    "        for key in curr_error:\n",
    "            error_diff_dict[key] = np.absolute((prev_error[key])[0] - (curr_error[key])[0])\n",
    "\n",
    "        # max_iter - 1 because already went through one iteration\n",
    "        for i in range(self.max_iter-1):\n",
    "            for values in error_diff_dict.values():\n",
    "                if float(values) > self.tol:\n",
    "                    self._update_centroids(mat)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "\n",
    "    def predict(self, mat: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Predicts the cluster labels for a provided matrix of data points--\n",
    "            question: what sorts of data inputs here would prevent the code from running?\n",
    "            How would you catch these sorts of end-user related errors?\n",
    "            What if, for example, the matrix is of a different number of features than\n",
    "            the data that the clusters were fit on?\n",
    "\n",
    "        inputs:\n",
    "            mat: np.ndarray\n",
    "                A 2D matrix where the rows are observations and columns are features\n",
    "\n",
    "        outputs:\n",
    "            np.ndarray\n",
    "                a 1D array with the cluster label for each of the observations in `mat`\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mat.ndim == 2\n",
    "        except TypeError:\n",
    "            print('Incorrect number of dimensions:' + mat.ndim)\n",
    "\n",
    "        new_assign = self._assign_cluster(mat)\n",
    "\n",
    "        for key, data_list in new_assign.items():\n",
    "            key, values = zip(*data_list)  # Unpack\n",
    "            plt.scatter(key, values, label=key)\n",
    "        plt.show()\n",
    "\n",
    "    def get_error(self) -> float:\n",
    "        \"\"\"\n",
    "        Returns the final squared-mean error of the fit model. You can either do this by storing the\n",
    "        original dataset or recording it following the end of model fitting.\n",
    "\n",
    "        outputs:\n",
    "            float\n",
    "                the squared-mean error of the fit model\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def get_centroids(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the centroid locations of the fit model.\n",
    "\n",
    "        outputs:\n",
    "            np.ndarray\n",
    "                a `k x m` 2D matrix representing the cluster centroids of the fit model\n",
    "        \"\"\"\n",
    "        return self.centroids\n",
    "\n",
    "    def _generate_init_centroid(self, mat: np.ndarray):\n",
    "        self.centroids = []\n",
    "        initial_index = np.random.choice(range(mat.shape[0]), )\n",
    "        self.centroids.append(mat[initial_index, :].tolist())\n",
    "\n",
    "    def distance_from_centroids(self, mat: np.ndarray):\n",
    "        centroids = self.centroids\n",
    "        dist = cdist(mat, np.array(self.centroids))\n",
    "\n",
    "        # Already calculating (minimum) distance between points in mat and closest centroid\n",
    "        dist_squared = np.array([min([np.linalg.norm(m-c)**2 for c in centroids]) for m in mat])\n",
    "        self.dist_squared = dist_squared\n",
    "        return self.dist_squared\n",
    "\n",
    "    def _distance_from_centroids(self, mat: np.ndarray):\n",
    "        centroids = self.centroids\n",
    "        dist = cdist(mat, np.array(self.centroids))\n",
    "\n",
    "        # Already calculating (minimum) distance between points in mat and closest centroid\n",
    "        dist_squared = np.array([min([np.linalg.norm(m-c)**2 for c in centroids]) for m in mat])\n",
    "        self.dist_squared = dist_squared\n",
    "\n",
    "    def _choose_next_centroid(self, mat: np.ndarray):\n",
    "        self.probs = self.dist_squared / self.dist_squared.sum()\n",
    "        self.cumulative_probs = self.probs.cumsum()\n",
    "        r = np.random.uniform(low=0.0, high=1.0)\n",
    "        index = np.where(self.cumulative_probs >= r)[0][0]\n",
    "        return mat[index]\n",
    "\n",
    "    def _generate_k_centroids(self, mat: np.ndarray):\n",
    "        self._generate_init_centroid(mat)\n",
    "        while len(self.centroids) < self.k:\n",
    "            self._distance_from_centroids(mat)\n",
    "            self.centroids.append(self._choose_next_centroid(mat))\n",
    "        self.centroids = np.array(self.centroids)\n",
    "\n",
    "    def _determine_error(self, mat: np.ndarray) -> np.ndarray:\n",
    "        centroids = self.get_centroids()\n",
    "        sum_of_squares_error = np.array([np.square([np.sum((m-c)**2) for c in centroids]) for m in mat])\n",
    "        return sum_of_squares_error\n",
    "\n",
    "    def _assign_cluster(self, mat: np.ndarray) -> defaultdict:\n",
    "\n",
    "        # I created a dictionary assigning each point to the centroid for which error is minimum\n",
    "        assignment_dict = defaultdict(list)\n",
    "\n",
    "        error = self._determine_error(mat)\n",
    "\n",
    "        for index, val in enumerate(error):\n",
    "            min_dist_index = np.argmin(error[index])\n",
    "            assignment_dict[min_dist_index].append(mat[index])\n",
    "\n",
    "        return assignment_dict\n",
    "\n",
    "    def _update_centroids(self, mat: np.ndarray):\n",
    "        # Creates a dictionary in which keys are centroids and values are the data points assigned to them\n",
    "        class_dict = self._assign_cluster(mat)\n",
    "\n",
    "        # Initialize a dictionary with mean coordinates for each cluster center\n",
    "        mean_dict = defaultdict(list)\n",
    "\n",
    "        # Iterate through the k keys\n",
    "        for i in class_dict.keys():\n",
    "            # Pass the values of class_dict into a list and assign to dict_values\n",
    "            dict_values = list(class_dict.values())\n",
    "\n",
    "            # Select the values corresponding to the ith key\n",
    "            dict_values_curr = dict_values[i]\n",
    "\n",
    "            # Take the mean of all the n observations and m features across each data point in a particular cluster\n",
    "            dict_val_mean = map(np.mean, zip(*dict_values_curr))\n",
    "\n",
    "            # Make dict_val_mean a list\n",
    "            dict_val_mean = list(dict_val_mean)\n",
    "\n",
    "            # Append mean_dict with the mean associated with the m and n values\n",
    "            mean_dict[i].append(dict_val_mean)\n",
    "\n",
    "        # Reset self.centroids to be empty\n",
    "        self.centroids = []\n",
    "\n",
    "        # Loop through the number of centroids until you have added k centroids\n",
    "        while len(self.centroids) < self.k:\n",
    "\n",
    "            # Iterate through mean_dict\n",
    "            for key, value in mean_dict.items():\n",
    "                # Assign the k key values to be indices for the self.centroids array\n",
    "                index = key\n",
    "                # Insert the associated mean values to a specific index\n",
    "                self.centroids.insert(index, value)\n",
    "\n",
    "        # Reshape self.centroids array to be m x n dimensions\n",
    "        self.centroids = np.squeeze(np.array(self.centroids), axis=(1,))\n",
    "\n",
    "    def _generate_error_per_centroid(self, mat: np.ndarray):\n",
    "        # Returns dictionary of summed errors per cluster\n",
    "        error_dict = defaultdict(list)\n",
    "        error = self._determine_error(mat)\n",
    "        for index, val in enumerate(error):\n",
    "            min_dist_index = np.argmin(error[index])\n",
    "            error_dict[min_dist_index].append(val[min_dist_index])\n",
    "\n",
    "        # Calculate error of all assigned points in a particular cluster\n",
    "        sum_errors_dict = {k: [sum(error_dict[k])] for k in error_dict.keys()}\n",
    "\n",
    "        return sum_errors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d06ff6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansplusplus = Kplusplus(3, tol=1e-6, max_iter=100)\n",
    "mat, labels = make_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93b3fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeansplusplus.fit(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25398944",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'scatter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkmeansplusplus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 69\u001b[0m, in \u001b[0;36mKplusplus.predict\u001b[0;34m(self, mat)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, data_list \u001b[38;5;129;01min\u001b[39;00m new_assign\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     68\u001b[0m     key, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mdata_list)  \u001b[38;5;66;03m# Unpack\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m(key, values, label\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m     70\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'scatter'"
     ]
    }
   ],
   "source": [
    "kmeansplusplus.predict(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3382f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
